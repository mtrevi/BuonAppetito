{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "from ext.LIWClib.EmotionsLIWClib import *\n",
    "# from ext.TextProcessingLib.TextProcessing import *\n",
    "# from data.YelpDataLoader import *\n",
    "from ext.GensimSemanticLib.GensimStatisticalProcessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED - ({'posemo': 0, 'negemo': 3}) This pasta sucks, it is made by shit. I don't like this pizza.\n",
      "PASSED - ({'posemo': 0, 'negemo': 0}) Questa passata fa schifo!\n",
      "PASSED - ({'posemo': 1, 'negemo': 2}) This restaurant has all my love but the food is not good and the service is terrible!\n"
     ]
    }
   ],
   "source": [
    "myLIWC = LIWCObj()\n",
    "myLIWC.build_model('/Users/trevi/Projects/libs/LIWClib/dictionary/LIWC2007_English100131.dic')\n",
    "myLIWC.unittest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M0 = 'data/food_dataset.w2v/food_bbc_1count_100size.model'\n",
    "M4 = 'data/food_dataset.w2v/w2v-food-bbc_menupages-1count_300size.notstem.model'\n",
    "M5 = 'data/food_dataset.w2v/w2v-food-bbc_menupages-3count_300size.notstem.model'\n",
    "gs0 = GensimCore(); gs0.load_model( M0 )\n",
    "gs4 = GensimCore(); gs4.load_model( M4 )\n",
    "gs5 = GensimCore(); gs5.load_model( M5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lasagn', 0.8531348705291748),\n",
       " ('challeng', 0.7936052083969116),\n",
       " ('rick', 0.7791990041732788),\n",
       " ('glass', 0.7713647484779358),\n",
       " ('flottant', 0.7638132572174072),\n",
       " ('feel', 0.7623695135116577),\n",
       " ('langoustin_claw', 0.7620701789855957),\n",
       " ('effort', 0.7575380802154541),\n",
       " ('dian', 0.7571722269058228),\n",
       " ('stein', 0.7553558349609375)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs0.model.most_similar(positive=['wine'], negative=[])\n",
    "gs0.model.most_similar(positive=['carbonara','pesto'], negative=['meat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pasta quattro formaggi sucks made shit dont like pizza marinara\n",
      "sim(pasta,quattro): 0.523518417298\n",
      "\"quattro\"\n",
      "[('san', 0.744605541229248), ('ankake', 0.6891857981681824), ('santa', 0.6820037961006165)]\n",
      "sim(quattro,formaggi): 0.59263812548\n",
      "\"formaggi\"\n",
      "[('daniele', 0.9198753237724304), ('prosciutto_month', 0.7697910666465759), ('tamales_oaxaquenos', 0.7602232098579407)]\n",
      "sim(formaggi,sucks): sim(sucks,made): sim(made,shit): sim(shit,dont): sim(dont,like): 0.768308795026\n",
      "\"like\"\n",
      "[('boozesoaked', 0.9256796836853027), ('complemented', 0.9230676293373108), ('vilest', 0.9187042713165283)]\n",
      "sim(like,pizza): -0.14485438334\n",
      "\"pizza\"\n",
      "[('pizza_burger', 0.8487417697906494), ('pepperoni', 0.7726970911026001), ('rustica', 0.7643126249313354)]\n",
      "sim(pizza,marinara): 0.47269333301\n",
      "\"marinara\"\n",
      "[('bufala', 0.826797604560852), ('penne', 0.809898853302002), ('mozzarella_sticks', 0.8022845983505249)]\n"
     ]
    }
   ],
   "source": [
    "ss = \"This pasta quattro formaggi sucks, it is made by shit. I don't like this pizza marinara.\"\n",
    "ss_proc = preprocess_pipeline(ss, stemmer_type=None, do_remove_stopwords=True, noAccents=True, return_as_str=True)\n",
    "print ss_proc\n",
    "#\n",
    "found_food = False\n",
    "l_words = tokenize2words(ss_proc)\n",
    "for i in range(1,len(l_words)):\n",
    "    ## get food items\n",
    "    pw = l_words[i-1]\n",
    "    cw = l_words[i]\n",
    "    try:\n",
    "        print 'sim(%s,%s):' %(pw,cw), gs4.model.similarity(pw, cw)\n",
    "        print '\"%s\"' %cw\n",
    "        print gs4.model.most_similar(positive=[cw])[:3]\n",
    "    except:\n",
    "#         print '- not found'\n",
    "        continue\n",
    "if found_food:\n",
    "    ## get sentimens\n",
    "    print myLIWC.getCategoriesFromText(ss_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pasta', 'NN'), ('quattro', 'NN'), ('formaggi', 'NN'), ('sucks', 'NNS'), ('made', 'VBN'), ('shit', 'NN')]\n",
      "['pasta', 'quattro', 'formaggi', 'sucks', 'made', 'shit'] -> (0.50) quattro formaggi\n",
      "{'posemo': 0, 'negemo': 2}\n",
      "[('dont', 'NN'), ('like', 'IN'), ('pizza', 'NN'), ('marinara', 'NN')]\n",
      "['dont', 'like', 'pizza', 'marinara'] -> (0.33) pizza\n",
      "{'posemo': 0, 'negemo': 1}\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag, ne_chunk\n",
    "for sent in tokenize2sentences2words(ss):\n",
    "    l_words = remove_stopwords(sent)\n",
    "    ## select only nouns from l_words\n",
    "    print pos_tag( l_words )\n",
    "    l_nouns = [word for word,pos in pos_tag( l_words ) if pos == 'NN']\n",
    "    ## match each word with food\n",
    "    matches = ''\n",
    "    topjac = -1\n",
    "    for fw in food.keys():\n",
    "      jac = jaccard_distance( l_nouns, fw.split(' ') )\n",
    "      if jac > topjac:\n",
    "        topjac = jac        \n",
    "        matches = fw\n",
    "    ## check matches\n",
    "    print l_words, '-> (%.2f)' %topjac, matches\n",
    "    print myLIWC.getCategoriesFromText(' '.join(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " en\n",
      "[(u'This', u'DT'), (u'pasta', u'NN'), (u'quattro', u'NN'), (u'formaggi', u'NN'), (u'sucks', u'VBZ'), (u'it', u'PRP'), (u'is', u'VBZ'), (u'made', u'VBN'), (u'by', u'IN'), (u'shit', u'NN'), (u'I', u'PRP'), (u'do', u'VBP'), (u'n', u'NN'), (u\"'\", u'POS'), (u't', u'NN'), (u'like', u'IN'), (u'this', u'DT'), (u'pizza', u'NN'), (u'marinara', u'NN')]\n",
      "[u'pasta quattro formaggi sucks', u'pizza marinara']\n",
      "This pasta quattro formaggi sucks, it is made by shit.\n",
      "-> -0.25\n",
      "-> {'posemo': 0, 'negemo': 2}\n",
      "I don't like this pizza marinara.\n",
      "-> 0.0\n",
      "-> {'posemo': 0, 'negemo': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Esta formaggi quattro pastas chupa , se hace por una mierda. No me gusta este marinara pizza.\")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Playing with TextBlob\n",
    "# http://textblob.readthedocs.org/en/dev/\n",
    "from textblob import TextBlob\n",
    "text = \"This pasta quattro formaggi sucks, it is made by shit. I don't like this pizza marinara.\"\n",
    "blob = TextBlob(text)\n",
    "print blob.detect_language()\n",
    "print blob.tags           # [('The', 'DT'), ('titular', 'JJ'),\n",
    "                    #  ('threat', 'NN'), ('of', 'IN'), ...]\n",
    "\n",
    "print blob.noun_phrases   # WordList(['titular threat', 'blob',\n",
    "                    #            'ultimate movie monster',\n",
    "                    #            'amoeba-like mass', ...])\n",
    "\n",
    "for sentence in blob.sentences:\n",
    "    print sentence\n",
    "    print '->', sentence.sentiment.polarity\n",
    "    print '->', myLIWC.getCategoriesFromText( str(sentence) )\n",
    "# 0.060\n",
    "# -0.341\n",
    "\n",
    "blob.translate(to=\"es\")  # 'La amenaza titular de The Blob...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Business Container (data/yelp_restaurants_business.p)\n",
      "\t-> loaded 21892 business\n",
      "Loading Review Container (data/yelp_restaurants_review.p)\n",
      "\t-> loaded 990627 reviews\n",
      "loaded trie\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load Business and Review processed data\n",
    "'''\n",
    "YBFILE = 'data/yelp_restaurants_business.p'\n",
    "YRFILE = 'data/yelp_restaurants_review.p'\n",
    "print 'Loading Business Container (%s)' %YBFILE\n",
    "businessContainer = pickle.load( open( YBFILE, \"rb\" ) )\n",
    "print '\\t-> loaded %d business' %businessContainer.len()\n",
    "print 'Loading Review Container (%s)' %YRFILE\n",
    "reviewContainer = pickle.load( open( YRFILE, \"rb\" ) )\n",
    "print '\\t-> loaded %d reviews' %reviewContainer.len()\n",
    "from data.food_dataset.trieFinder import *\n",
    "## load trie\n",
    "trie = json.load(open('data/food_dataset/bbc_menupages-trie.json'))\n",
    "trie_finder = TrieFinder(trie)\n",
    "print 'loaded trie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "the fish was very good but the reuben was to die for :\n",
      "\t-> [u'fish', u'reuben'] -> {'posemo': 1, 'negemo': 0}\n",
      "both dishes were massive and could very easily be shared between two people :\n",
      "\t-> [u'two'] -> {'posemo': 2, 'negemo': 0}\n",
      "------\n",
      "cant miss stop for the best fish sandwich in pittsburgh :\n",
      "\t-> [u'fish sandwich'] -> {'posemo': 2, 'negemo': 0}\n",
      "------\n",
      "fish sandwiich salmon huge and delicious flounder shrimp a few ways norfolk style is oily for my taste and i never had it growing up in norfolk :\n",
      "\t-> [u'fish', u'salmon', u'shrimp'] -> {'posemo': 1, 'negemo': 0}\n",
      "hawkins st special prime rib sized for two watch it the prices are low the portions are large and just about everything on the menu is delicious :\n",
      "\t-> [u'special', u'prime rib', u'two'] -> {'posemo': 2, 'negemo': 1}\n",
      "------\n",
      "i had the fish sandwich which was great :\n",
      "\t-> [u'fish sandwich'] -> {'posemo': 1, 'negemo': 0}\n",
      "------\n",
      "the best fish and chips youll ever enjoy and equally superb fried shrimp :\n",
      "\t-> [u'fish', u'fried shrimp'] -> {'posemo': 2, 'negemo': 0}\n",
      "a great out of the way non corporate vestige of americana :\n",
      "\t-> [u'americana'] -> {'posemo': 1, 'negemo': 0}\n",
      "------\n",
      "shes very nice all employees are super nice service was excellent i had the fish sandwich my girlfriend had the ruben more than you could possibly eat very reasonable prices :\n",
      "\t-> [u'fish sandwich'] -> {'posemo': 4, 'negemo': 0}\n",
      "------\n",
      "wonderful reuben :\n",
      "\t-> [u'reuben'] -> {'posemo': 1, 'negemo': 0}\n",
      "------\n",
      "good fish sandwich :\n",
      "\t-> [u'fish sandwich'] -> {'posemo': 1, 'negemo': 0}\n",
      "------\n",
      "after a morning of thrift store hunting a friend and i were thinking of lunch and he suggested emils after hed seen chris sebak do a bit on it and had tried it a time or two before and i had not :\n",
      "\t-> [u'two'] -> {'posemo': 1, 'negemo': 0}\n",
      "and yet another shot at finding a decent reuben in da burgh well thats like hunting the holy grail :\n",
      "\t-> [u'shot', u'reuben'] -> {'posemo': 2, 'negemo': 0}\n",
      "oh and any big burrito sousa foodies might as well stop reading now :\n",
      "\t-> [u'burrito'] -> {'posemo': 1, 'negemo': 0}\n",
      "plain with a dark wood bar on one side plain white walls with no yinzer pics good sturdy chairs and actual white linens on the tables :\n",
      "\t-> [u'plain', u'plain', u'white', u'white'] -> {'posemo': 0, 'negemo': 1}\n",
      "this is the kind of neighborhood dive that i could see frank and dino pulling a few tables together for some poker a fish sammich and some cheap scotch :\n",
      "\t-> [u'fish'] -> {'posemo': 1, 'negemo': 0}\n",
      "we each had a reuben and my friend had a side of fries :\n",
      "\t-> [u'reuben'] -> {'posemo': 1, 'negemo': 0}\n",
      "a little too thick on the bread but overall tasty and definitely filling :\n",
      "\t-> [u'bread'] -> {'posemo': 1, 'negemo': 0}\n",
      "i seriously crave a true good ny reuben but since i cant afford to travel right now what i find in da burgh will have to do :\n",
      "\t-> [u'reuben'] -> {'posemo': 2, 'negemo': 1}\n",
      "fish sandwiches piled with breaded fish that looked amazing :\n",
      "\t-> [u'fish', u'fish'] -> {'posemo': 1, 'negemo': 0}\n",
      "my friend also mentioned that they have a chicken parm special one day of the week that is only served until 4 pm and that it is fantastic :\n",
      "\t-> [u'chicken', u'special'] -> {'posemo': 3, 'negemo': 0}\n",
      "emils is no frills good portions very reasonable prices very comfortable neighborhood hole in the wall kind of like cheers but in a blue collar neighborhood in the 1950s :\n",
      "\t-> [u'collar'] -> {'posemo': 4, 'negemo': 1}\n",
      "a pound of fish on a fish shaped bun as opposed to da burghs seemingly popular hamburger bun :\n",
      "\t-> [u'fish', u'fish', u'bun', u'hamburger', u'bun'] -> {'posemo': 1, 'negemo': 0}\n",
      "the fish was flavorful the batter excellent and for just 8 :\n",
      "\t-> [u'fish'] -> {'posemo': 1, 'negemo': 0}\n",
      "this may have been the best fish sandwich ive yet to have in da burgh :\n",
      "\t-> [u'fish sandwich'] -> {'posemo': 1, 'negemo': 0}\n",
      "------\n",
      "my boyfriend got the fish sandwich he enjoyed it as well"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching food-items in reviews\n",
      "\t-> found 0 rev_with_food (0 tot_food_sentences, 0 rev_no_food, 0 rev_no_text)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :\n",
      "\t-> [u'fish sandwich'] -> {'posemo': 2, 'negemo': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Parse Review Objects searching for food items\n",
    "'''\n",
    "print >> sys.stderr, 'Searching food-items in reviews'\n",
    "food_sentences = 0\n",
    "rev_with_food = 0\n",
    "rev_no_text = 0\n",
    "rev_no_food = 0\n",
    "lines = 0\n",
    "for revObj in reviewContainer.entries:\n",
    "  rev = revObj.text\n",
    "  print \"------\"\n",
    "  if len(rev.split(' ')) < 3:\n",
    "    rev_no_text += 1\n",
    "    print \"[!] no text\"\n",
    "    continue\n",
    "  lines += 1\n",
    "  ## splint in sentences, then in words\n",
    "  for sent in tokenize2sentences2words( rev ):\n",
    "    l_words = remove_stopwords( sent )\n",
    "    ## select only nouns from l_words\n",
    "    l_nouns = filter_POS_type( l_words, 'NN' )\n",
    "    ## match each word with food\n",
    "    matches = ''\n",
    "    topjac = -1\n",
    "    ##\n",
    "    nouns_food_tmp = trie_finder.find(l_words)\n",
    "    ## clean:\n",
    "    nouns_food = []\n",
    "    for nf in nouns_food_tmp:\n",
    "        if len(filter_POS_type(nf, 'NN')) > 0:\n",
    "            nouns_food.append(nf)\n",
    "    if len(nouns_food) > 0:\n",
    "        emot = myLIWC.getCategoriesFromText(' '.join(sent))\n",
    "        if emot['posemo'] != emot['negemo']:\n",
    "            print ' '.join(sent), ':'\n",
    "            print '\\t->', nouns_food, '->', emot\n",
    "  ##\n",
    "  if lines >= 10:\n",
    "    break\n",
    "  if lines % 100 == 0:\n",
    "    print >> sys.stderr, '\\t-> found %s rev_with_food (%s tot_food_sentences, %d rev_no_food, %d rev_no_text)' \\\n",
    "    %(rev_with_food, food_sentences, rev_no_food, rev_no_text)\n",
    "##\n",
    "print >> sys.stderr, '\\t-> found %s rev_with_food (%s tot_food_sentences, %d rev_no_food, %d rev_no_text)' \\\n",
    "%(rev_with_food, food_sentences, rev_no_food, rev_no_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "['dishes', 'massive', 'large', 'two', 'could', 'easily', 'shared', 'two', 'people', ':', 'cant', 'miss', 'stop', 'best', 'fish', 'sandwich', 'pittsburgh']\n",
      "['two', 'two', 'fish sandwich']\n",
      "---\n",
      "['miss', 'stop', 'sandwich', 'pittsburgh']\n",
      "['sandwich']\n",
      "---\n",
      "['two', 'two', 'fish sandwich']\n"
     ]
    }
   ],
   "source": [
    "sent = 'both dishes were massive large and two could very easily be shared between two people : \\\n",
    "cant miss stop for the best fish sandwich in pittsburgh'.split(' ')\n",
    "l_words = remove_stopwords( sent )\n",
    "print '---'\n",
    "print l_words\n",
    "print trie_finder.find(l_words)\n",
    "## select only nouns from l_words\n",
    "l_nouns = filter_POS_type( l_words, 'NN' )\n",
    "print '---'\n",
    "print l_nouns\n",
    "print trie_finder.find(l_nouns)\n",
    "print '---'\n",
    "cleaning = []\n",
    "for tf in trie_finder.find(l_words):\n",
    "    if len(filter_POS_type(tf,'NN')) > 0:\n",
    "        cleaning.append(tf)\n",
    "print cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## load trie\n",
    "# trie = json.load(open('data/food_dataset/bbc_menupages-trie.json'))\n",
    "# trie_finder = TrieFinder(trie)\n",
    "# print 'loaded trie'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
