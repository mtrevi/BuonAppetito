{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from model import *\n",
    "## Parameters\n",
    "CONFILE = \"BuonAppetito.conf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[found] Loading Business Container (../data/yelp_restaurants_business.p)\n",
      "\t-> loaded 21892 business\n",
      "Copying Business Ids into a Dictionary\n",
      "\t-> get 21892 business ids\n",
      "Generating Review Container (from: ../data/yelp_academic_dataset_review.json)\n",
      "\t-> loaded 60409 reviews (6.37%)\n",
      "\t-> loaded 119837 reviews (12.74%)\n",
      "\t-> loaded 178853 reviews (19.12%)\n",
      "\t-> loaded 235405 reviews (25.49%)\n",
      "\t-> loaded 310496 reviews (31.86%)\n",
      "\t-> loaded 372509 reviews (38.23%)\n",
      "\t-> loaded 433580 reviews (44.61%)\n",
      "\t-> loaded 502211 reviews (50.98%)\n",
      "\t-> loaded 565662 reviews (57.35%)\n",
      "\t-> loaded 631578 reviews (63.72%)\n",
      "\t-> loaded 685970 reviews (70.10%)\n",
      "\t-> loaded 752837 reviews (76.47%)\n",
      "\t-> loaded 819172 reviews (82.84%)\n",
      "\t-> loaded 882502 reviews (89.21%)\n",
      "\t-> loaded 945636 reviews (95.59%)\n",
      "\t-> loaded 990627 reviews (578637 discarded)\n",
      "\t-> saving review container (to \"../data/yelp_restaurants_review.p\")\n",
      "Generating User Container (from: ../data/yelp_academic_dataset_user.json)\n",
      "\t-> loaded 30000 reviews (8.18%)\n",
      "\t-> loaded 60000 reviews (16.36%)\n",
      "\t-> loaded 90000 reviews (24.54%)\n",
      "\t-> loaded 120000 reviews (32.72%)\n",
      "\t-> loaded 150000 reviews (40.90%)\n",
      "\t-> loaded 180000 reviews (49.08%)\n",
      "\t-> loaded 210000 reviews (57.27%)\n",
      "\t-> loaded 240000 reviews (65.45%)\n",
      "\t-> loaded 270000 reviews (73.63%)\n",
      "\t-> loaded 300000 reviews (81.81%)\n",
      "\t-> loaded 330000 reviews (89.99%)\n",
      "\t-> loaded 360000 reviews (98.17%)\n",
      "\t-> loaded 366715 users\n",
      "\t-> saving user container (to \"../data/yelp_restaurants_users.p\")\n"
     ]
    }
   ],
   "source": [
    "# __name__ : DataProcessing\n",
    "# Import module for Yelp Data loading and conversion\n",
    "from data_processing.YelpDataLoader import *\n",
    "dl = YelpDataLoader(CONFILE)\n",
    "dl.load_yelp_business()\n",
    "dl.load_yelp_review()\n",
    "dl.load_yelp_users()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4484)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# __name__ : SentimentAnalysis\n",
    "# Import the sentiment analysis module using LIWC\n",
    "from sentiment_analysis.LIWClib.EmotionsLIWClib import *\n",
    "myLIWC = LIWCObj()\n",
    "myLIWC.build_model('/Users/trevi/Projects/libs/LIWClib/dictionary/LIWC2007_English100131.dic')\n",
    "# myLIWC.unittest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# __name__ : YelpProfiles\n",
    "from profiles_builder.YelpProfiles import *\n",
    "profBuilder = YelpProfileBuilder()\n",
    "profBuilder.load_yelp_data()\n",
    "# Parse profiles, get the food-words and extract the sentiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# __name__ : NN_Approach\n",
    "# Import the NN (W2V) module for word-similarity\n",
    "from nn_approach.GensimSemanticLib.GensimStatisticalProcessing import *\n",
    "M0 = '../data/food_dataset.w2v/food_bbc_1count_100size.model'\n",
    "M4 = '../data/food_dataset.w2v/w2v-food-bbc_menupages-1count_300size.notstem.model'\n",
    "M5 = '../data/food_dataset.w2v/w2v-food-bbc_menupages-3count_300size.notstem.model'\n",
    "gs0 = GensimCore(); gs0.load_model( M0 )\n",
    "gs4 = GensimCore(); gs4.load_model( M4 )\n",
    "gs5 = GensimCore(); gs5.load_model( M5 )\n",
    "# gs0.model.most_similar(positive=['wine'], negative=[])\n",
    "# gs0.model.most_similar(positive=['carbonara','pesto'], negative=['meat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pasta quattro formaggi sucks made shit dont like pizza marinara\n",
      "sim(pasta,quattro): 0.523518417298\n",
      "\"quattro\"\n",
      "[('san', 0.744605541229248), ('ankake', 0.6891857981681824), ('santa', 0.6820037961006165)]\n",
      "sim(quattro,formaggi): 0.59263812548\n",
      "\"formaggi\"\n",
      "[('daniele', 0.9198753237724304), ('prosciutto_month', 0.7697910666465759), ('tamales_oaxaquenos', 0.7602232098579407)]\n",
      "sim(formaggi,sucks): sim(sucks,made): sim(made,shit): sim(shit,dont): sim(dont,like): 0.768308795026\n",
      "\"like\"\n",
      "[('boozesoaked', 0.9256796836853027), ('complemented', 0.9230676293373108), ('vilest', 0.9187042713165283)]\n",
      "sim(like,pizza): -0.14485438334\n",
      "\"pizza\"\n",
      "[('pizza_burger', 0.8487417697906494), ('pepperoni', 0.7726970911026001), ('rustica', 0.7643126249313354)]\n",
      "sim(pizza,marinara): 0.47269333301\n",
      "\"marinara\"\n",
      "[('bufala', 0.826797604560852), ('penne', 0.809898853302002), ('mozzarella_sticks', 0.8022845983505249)]\n"
     ]
    }
   ],
   "source": [
    "ss = \"This pasta quattro formaggi sucks, it is made by shit. I don't like this pizza marinara.\"\n",
    "ss_proc = preprocess_pipeline(ss, stemmer_type=None, do_remove_stopwords=True, noAccents=True, return_as_str=True)\n",
    "print ss_proc\n",
    "#\n",
    "found_food = False\n",
    "l_words = tokenize2words(ss_proc)\n",
    "for i in range(1,len(l_words)):\n",
    "    ## get food items\n",
    "    pw = l_words[i-1]\n",
    "    cw = l_words[i]\n",
    "    try:\n",
    "        print 'sim(%s,%s):' %(pw,cw), gs4.model.similarity(pw, cw)\n",
    "        print '\"%s\"' %cw\n",
    "        print gs4.model.most_similar(positive=[cw])[:3]\n",
    "    except:\n",
    "#         print '- not found'\n",
    "        continue\n",
    "if found_food:\n",
    "    ## get sentimens\n",
    "    print myLIWC.getCategoriesFromText(ss_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pasta', 'NN'), ('quattro', 'NN'), ('formaggi', 'NN'), ('sucks', 'NNS'), ('made', 'VBN'), ('shit', 'NN')]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'food' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b381ea48d2e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtopjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfood\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjaccard_distance\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0ml_nouns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mjac\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtopjac\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'food' is not defined"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag, ne_chunk\n",
    "for sent in tokenize2sentences2words(ss):\n",
    "    l_words = remove_stopwords(sent)\n",
    "    ## select only nouns from l_words\n",
    "    print pos_tag( l_words )\n",
    "    l_nouns = [word for word,pos in pos_tag( l_words ) if pos == 'NN']\n",
    "    ## match each word with food\n",
    "    matches = ''\n",
    "    topjac = -1\n",
    "    for fw in food.keys():\n",
    "      jac = jaccard_distance( l_nouns, fw.split(' ') )\n",
    "      if jac > topjac:\n",
    "        topjac = jac        \n",
    "        matches = fw\n",
    "    ## check matches\n",
    "    print l_words, '-> (%.2f)' %topjac, matches\n",
    "    print myLIWC.getCategoriesFromText(' '.join(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[(u'This', u'DT'), (u'pasta', u'NN'), (u'quattro', u'NN'), (u'formaggi', u'NN'), (u'sucks', u'VBZ'), (u'it', u'PRP'), (u'is', u'VBZ'), (u'made', u'VBN'), (u'by', u'IN'), (u'shit', u'NN'), (u'I', u'PRP'), (u'do', u'VBP'), (u'n', u'NN'), (u\"'\", u'POS'), (u't', u'NN'), (u'like', u'IN'), (u'this', u'DT'), (u'pizza', u'NN'), (u'marinara', u'NN')]\n",
      "[u'pasta quattro formaggi sucks', u'pizza marinara']\n",
      "This pasta quattro formaggi sucks, it is made by shit.\n",
      "-> -0.25\n",
      "-> {'posemo': 0, 'negemo': 2}\n",
      "I don't like this pizza marinara.\n",
      "-> 0.0\n",
      "-> {'posemo': 0, 'negemo': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextBlob(\"\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Playing with TextBlob\n",
    "# http://textblob.readthedocs.org/en/dev/\n",
    "from textblob import TextBlob\n",
    "text = \"This pasta quattro formaggi sucks, it is made by shit. I don't like this pizza marinara.\"\n",
    "blob = TextBlob(text)\n",
    "print blob.detect_language()\n",
    "print blob.tags           # [('The', 'DT'), ('titular', 'JJ'),\n",
    "                    #  ('threat', 'NN'), ('of', 'IN'), ...]\n",
    "\n",
    "print blob.noun_phrases   # WordList(['titular threat', 'blob',\n",
    "                    #            'ultimate movie monster',\n",
    "                    #            'amoeba-like mass', ...])\n",
    "\n",
    "for sentence in blob.sentences:\n",
    "    print sentence\n",
    "    print '->', sentence.sentiment.polarity\n",
    "    print '->', myLIWC.getCategoriesFromText( str(sentence) )\n",
    "# 0.060\n",
    "# -0.341\n",
    "\n",
    "blob.translate(to=\"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Business Container (data/yelp_restaurants_business.p)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named DataObjects.YelpBusinessData",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e1a78d01e169>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mYRFILE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/yelp_restaurants_review.p'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Loading Business Container (%s)'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mYBFILE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mbusinessContainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mYBFILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'\\t-> loaded %d business'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mbusinessContainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Loading Review Container (%s)'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mYRFILE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    859\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload_inst\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_instantiate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mINST\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_inst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;31m# Subclasses may override this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named DataObjects.YelpBusinessData"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load Business and Review processed data\n",
    "'''\n",
    "YBFILE = 'data/yelp_restaurants_business.p'\n",
    "YRFILE = 'data/yelp_restaurants_review.p'\n",
    "print 'Loading Business Container (%s)' %YBFILE\n",
    "businessContainer = pickle.load( open( YBFILE, \"rb\" ) )\n",
    "print '\\t-> loaded %d business' %businessContainer.len()\n",
    "print 'Loading Review Container (%s)' %YRFILE\n",
    "reviewContainer = pickle.load( open( YRFILE, \"rb\" ) )\n",
    "print '\\t-> loaded %d reviews' %reviewContainer.len()\n",
    "from data.food_dataset.trieFinder import *\n",
    "## load trie\n",
    "trie = json.load(open('data/food_dataset/bbc_menupages-trie.json'))\n",
    "trie_finder = TrieFinder(trie)\n",
    "print 'loaded trie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "the fish was very good but the reuben was to die for :\n",
      "\t-> [u'fish', u'reuben'] -> {'posemo': 1, 'negemo': 0}\n",
      "both dishes were massive and could very easily be shared between two people :\n",
      "\t-> [u'two'] -> {'posemo': 2, 'negemo': 0}\n",
      "------\n",
      "cant miss stop for the best fish sandwich in pittsburgh :\n",
      "\t-> [u'fish sandwich'] -> {'posemo': 2, 'negemo': 0}\n",
      "------\n",
      "fish sandwiich salmon huge and delicious flounder shrimp a few ways norfolk style is oily for my taste and i never had it growing up in norfolk :\n",
      "\t-> [u'fish', u'salmon', u'shrimp'] -> {'posemo': 1, 'negemo': 0}\n",
      "hawkins st special prime rib sized for two watch it the prices are low the portions are large and just about everything on the menu is delicious :\n",
      "\t-> [u'special', u'prime rib', u'two'] -> {'posemo': 2, 'negemo': 1}\n",
      "------\n",
      "i had the fish sandwich which was great :\n",
      "\t-> [u'fish sandwich'] -> {'posemo': 1, 'negemo': 0}\n",
      "------\n",
      "the best fish and chips youll ever enjoy and equally superb fried shrimp :\n",
      "\t-> [u'fish', u'fried shrimp'] -> {'posemo': 2, 'negemo': 0}\n",
      "a great out of the way non corporate vestige of americana :\n",
      "\t-> [u'americana'] -> {'posemo': 1, 'negemo': 0}\n",
      "------\n",
      "shes very nice all employees are super nice service was excellent i had the fish sandwich my girlfriend had the ruben more than you could possibly eat very reasonable prices :\n",
      "\t-> [u'fish sandwich'] -> {'posemo': 4, 'negemo': 0}\n",
      "------\n",
      "wonderful reuben :\n",
      "\t-> [u'reuben'] -> {'posemo': 1, 'negemo': 0}\n",
      "------\n",
      "good fish sandwich :\n",
      "\t-> [u'fish sandwich'] -> {'posemo': 1, 'negemo': 0}\n",
      "------\n",
      "after a morning of thrift store hunting a friend and i were thinking of lunch and he suggested emils after hed seen chris sebak do a bit on it and had tried it a time or two before and i had not :\n",
      "\t-> [u'two'] -> {'posemo': 1, 'negemo': 0}\n",
      "and yet another shot at finding a decent reuben in da burgh well thats like hunting the holy grail :\n",
      "\t-> [u'shot', u'reuben'] -> {'posemo': 2, 'negemo': 0}\n",
      "oh and any big burrito sousa foodies might as well stop reading now :\n",
      "\t-> [u'burrito'] -> {'posemo': 1, 'negemo': 0}\n",
      "plain with a dark wood bar on one side plain white walls with no yinzer pics good sturdy chairs and actual white linens on the tables :\n",
      "\t-> [u'plain', u'plain', u'white', u'white'] -> {'posemo': 0, 'negemo': 1}\n",
      "this is the kind of neighborhood dive that i could see frank and dino pulling a few tables together for some poker a fish sammich and some cheap scotch :\n",
      "\t-> [u'fish'] -> {'posemo': 1, 'negemo': 0}\n",
      "we each had a reuben and my friend had a side of fries :\n",
      "\t-> [u'reuben'] -> {'posemo': 1, 'negemo': 0}\n",
      "a little too thick on the bread but overall tasty and definitely filling :\n",
      "\t-> [u'bread'] -> {'posemo': 1, 'negemo': 0}\n",
      "i seriously crave a true good ny reuben but since i cant afford to travel right now what i find in da burgh will have to do :\n",
      "\t-> [u'reuben'] -> {'posemo': 2, 'negemo': 1}\n",
      "fish sandwiches piled with breaded fish that looked amazing :\n",
      "\t-> [u'fish', u'fish'] -> {'posemo': 1, 'negemo': 0}\n",
      "my friend also mentioned that they have a chicken parm special one day of the week that is only served until 4 pm and that it is fantastic :\n",
      "\t-> [u'chicken', u'special'] -> {'posemo': 3, 'negemo': 0}\n",
      "emils is no frills good portions very reasonable prices very comfortable neighborhood hole in the wall kind of like cheers but in a blue collar neighborhood in the 1950s :\n",
      "\t-> [u'collar'] -> {'posemo': 4, 'negemo': 1}\n",
      "a pound of fish on a fish shaped bun as opposed to da burghs seemingly popular hamburger bun :\n",
      "\t-> [u'fish', u'fish', u'bun', u'hamburger', u'bun'] -> {'posemo': 1, 'negemo': 0}\n",
      "the fish was flavorful the batter excellent and for just 8 :\n",
      "\t-> [u'fish'] -> {'posemo': 1, 'negemo': 0}\n",
      "this may have been the best fish sandwich ive yet to have in da burgh :\n",
      "\t-> [u'fish sandwich'] -> {'posemo': 1, 'negemo': 0}\n",
      "------\n",
      "my boyfriend got the fish sandwich he enjoyed it as well"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching food-items in reviews\n",
      "\t-> found 0 rev_with_food (0 tot_food_sentences, 0 rev_no_food, 0 rev_no_text)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :\n",
      "\t-> [u'fish sandwich'] -> {'posemo': 2, 'negemo': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Parse Review Objects searching for food items\n",
    "'''\n",
    "print >> sys.stderr, 'Searching food-items in reviews'\n",
    "food_sentences = 0\n",
    "rev_with_food = 0\n",
    "rev_no_text = 0\n",
    "rev_no_food = 0\n",
    "lines = 0\n",
    "for revObj in reviewContainer.entries:\n",
    "  rev = revObj.text\n",
    "  print \"------\"\n",
    "  if len(rev.split(' ')) < 3:\n",
    "    rev_no_text += 1\n",
    "    print \"[!] no text\"\n",
    "    continue\n",
    "  lines += 1\n",
    "  ## splint in sentences, then in words\n",
    "  for sent in tokenize2sentences2words( rev ):\n",
    "    l_words = remove_stopwords( sent )\n",
    "    ## select only nouns from l_words\n",
    "    l_nouns = filter_POS_type( l_words, 'NN' )\n",
    "    ## match each word with food\n",
    "    matches = ''\n",
    "    topjac = -1\n",
    "    ##\n",
    "    nouns_food_tmp = trie_finder.find(l_words)\n",
    "    ## clean:\n",
    "    nouns_food = []\n",
    "    for nf in nouns_food_tmp:\n",
    "        if len(filter_POS_type(nf, 'NN')) > 0:\n",
    "            nouns_food.append(nf)\n",
    "    if len(nouns_food) > 0:\n",
    "        emot = myLIWC.getCategoriesFromText(' '.join(sent))\n",
    "        if emot['posemo'] != emot['negemo']:\n",
    "            print ' '.join(sent), ':'\n",
    "            print '\\t->', nouns_food, '->', emot\n",
    "  ##\n",
    "  if lines >= 10:\n",
    "    break\n",
    "  if lines % 100 == 0:\n",
    "    print >> sys.stderr, '\\t-> found %s rev_with_food (%s tot_food_sentences, %d rev_no_food, %d rev_no_text)' \\\n",
    "    %(rev_with_food, food_sentences, rev_no_food, rev_no_text)\n",
    "##\n",
    "print >> sys.stderr, '\\t-> found %s rev_with_food (%s tot_food_sentences, %d rev_no_food, %d rev_no_text)' \\\n",
    "%(rev_with_food, food_sentences, rev_no_food, rev_no_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "['dishes', 'massive', 'large', 'two', 'could', 'easily', 'shared', 'two', 'people', ':', 'cant', 'miss', 'stop', 'best', 'fish', 'sandwich', 'pittsburgh']\n",
      "['two', 'two', 'fish sandwich']\n",
      "---\n",
      "['miss', 'stop', 'sandwich', 'pittsburgh']\n",
      "['sandwich']\n",
      "---\n",
      "['two', 'two', 'fish sandwich']\n"
     ]
    }
   ],
   "source": [
    "sent = 'both dishes were massive large and two could very easily be shared between two people : \\\n",
    "cant miss stop for the best fish sandwich in pittsburgh'.split(' ')\n",
    "l_words = remove_stopwords( sent )\n",
    "print '---'\n",
    "print l_words\n",
    "print trie_finder.find(l_words)\n",
    "## select only nouns from l_words\n",
    "l_nouns = filter_POS_type( l_words, 'NN' )\n",
    "print '---'\n",
    "print l_nouns\n",
    "print trie_finder.find(l_nouns)\n",
    "print '---'\n",
    "cleaning = []\n",
    "for tf in trie_finder.find(l_words):\n",
    "    if len(filter_POS_type(tf,'NN')) > 0:\n",
    "        cleaning.append(tf)\n",
    "print cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## load trie\n",
    "# trie = json.load(open('data/food_dataset/bbc_menupages-trie.json'))\n",
    "# trie_finder = TrieFinder(trie)\n",
    "# print 'loaded trie'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
